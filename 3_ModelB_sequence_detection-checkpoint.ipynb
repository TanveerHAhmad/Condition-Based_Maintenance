{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lion_data_upper_annular_train = pd.read_csv(r'lion_data_upper_annular_train_cluster1.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Sequence of 4 scoring function definition\n",
    "## >>> Why scoring function is required? Logic!\n",
    "def seqof4_scoring(data):\n",
    "    data = '_'.join(map(str, data))\n",
    "    data = data + str('_')\n",
    "\n",
    "    score_dataset = pd.DataFrame()\n",
    "\n",
    "    for a in range(0, 3):\n",
    "        for b in range(0, 3):\n",
    "            for c in range(0, 3):\n",
    "                for d in range(0, 3):\n",
    "                    pattern1 = str('(?=(') + str(a) + str('_') + str(b) + str('_') + str(c) + str('_') + str('))')\n",
    "                    pattern2 = str('(?=(') + str(a) + str('_') + str(b) + str('_') + str(c) + str('_') + str(d) + str('_') + str('))')\n",
    "                    ptrn = str(a) + str('_') + str(b) + str('_') + str(c) + str('_') + str(d) + str('_')\n",
    "                    freq_pattern1 = len(re.findall(pattern1, data))\n",
    "                    freq_pattern2 = len(re.findall(pattern2, data))\n",
    "                    if freq_pattern1 == 0:\n",
    "                        prb = 0\n",
    "                    else:\n",
    "                        prb = freq_pattern2 / freq_pattern1\n",
    "                    score_dataset = score_dataset.append(pd.DataFrame([[ptrn, prb]]))\n",
    "                    print(ptrn)\n",
    "\n",
    "    score_dataset.columns = ['seqof4_pattern', 'probability_score']\n",
    "    return score_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Open current sequence of states detection model\n",
    "X_train = np.array(lion_data_upper_annular_train['upper_ann_open_current'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=3, random_state=0, max_iter = 600).fit(X_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hornet_data_upper_annular_train['open_current_states_kmean'] = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(r'UA_open_current_seq_detection_model.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(kmeans_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Close current sequence of states detection model\n",
    "X_train = np.array(hornet_data_upper_annular_train['upper_ann_close_current'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=3, random_state=0, max_iter = 600).fit(X_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hornet_data_upper_annular_train['close_current_states_kmean'] = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(r'UA_close_current_seq_detection_model.pkl', 'wb')\n",
    "pickle.dump(kmeans_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hornet_data_upper_annular_train.to_csv(r'hornet_data_upper_annular_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0_0_0_\n",
      "0_0_0_1_\n",
      "0_0_0_2_\n",
      "0_0_1_0_\n",
      "0_0_1_1_\n",
      "0_0_1_2_\n",
      "0_0_2_0_\n",
      "0_0_2_1_\n",
      "0_0_2_2_\n",
      "0_1_0_0_\n",
      "0_1_0_1_\n",
      "0_1_0_2_\n",
      "0_1_1_0_\n",
      "0_1_1_1_\n",
      "0_1_1_2_\n",
      "0_1_2_0_\n",
      "0_1_2_1_\n",
      "0_1_2_2_\n",
      "0_2_0_0_\n",
      "0_2_0_1_\n",
      "0_2_0_2_\n",
      "0_2_1_0_\n",
      "0_2_1_1_\n",
      "0_2_1_2_\n",
      "0_2_2_0_\n",
      "0_2_2_1_\n",
      "0_2_2_2_\n",
      "1_0_0_0_\n",
      "1_0_0_1_\n",
      "1_0_0_2_\n",
      "1_0_1_0_\n",
      "1_0_1_1_\n",
      "1_0_1_2_\n",
      "1_0_2_0_\n",
      "1_0_2_1_\n",
      "1_0_2_2_\n",
      "1_1_0_0_\n",
      "1_1_0_1_\n",
      "1_1_0_2_\n",
      "1_1_1_0_\n",
      "1_1_1_1_\n",
      "1_1_1_2_\n",
      "1_1_2_0_\n",
      "1_1_2_1_\n",
      "1_1_2_2_\n",
      "1_2_0_0_\n",
      "1_2_0_1_\n",
      "1_2_0_2_\n",
      "1_2_1_0_\n",
      "1_2_1_1_\n",
      "1_2_1_2_\n",
      "1_2_2_0_\n",
      "1_2_2_1_\n",
      "1_2_2_2_\n",
      "2_0_0_0_\n",
      "2_0_0_1_\n",
      "2_0_0_2_\n",
      "2_0_1_0_\n",
      "2_0_1_1_\n",
      "2_0_1_2_\n",
      "2_0_2_0_\n",
      "2_0_2_1_\n",
      "2_0_2_2_\n",
      "2_1_0_0_\n",
      "2_1_0_1_\n",
      "2_1_0_2_\n",
      "2_1_1_0_\n",
      "2_1_1_1_\n",
      "2_1_1_2_\n",
      "2_1_2_0_\n",
      "2_1_2_1_\n",
      "2_1_2_2_\n",
      "2_2_0_0_\n",
      "2_2_0_1_\n",
      "2_2_0_2_\n",
      "2_2_1_0_\n",
      "2_2_1_1_\n",
      "2_2_1_2_\n",
      "2_2_2_0_\n",
      "2_2_2_1_\n",
      "2_2_2_2_\n"
     ]
    }
   ],
   "source": [
    "##### Sequence of 4 pattern, Open current\n",
    "data = np.array(hornet_data_upper_annular_train['open_current_states_kmean'])\n",
    "temp_df_open_current = seqof4_scoring(data)\n",
    "temp_df_open_current.to_csv(r'seqof4_open_current_pattern_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0_0_0_\n",
      "0_0_0_1_\n",
      "0_0_0_2_\n",
      "0_0_1_0_\n",
      "0_0_1_1_\n",
      "0_0_1_2_\n",
      "0_0_2_0_\n",
      "0_0_2_1_\n",
      "0_0_2_2_\n",
      "0_1_0_0_\n",
      "0_1_0_1_\n",
      "0_1_0_2_\n",
      "0_1_1_0_\n",
      "0_1_1_1_\n",
      "0_1_1_2_\n",
      "0_1_2_0_\n",
      "0_1_2_1_\n",
      "0_1_2_2_\n",
      "0_2_0_0_\n",
      "0_2_0_1_\n",
      "0_2_0_2_\n",
      "0_2_1_0_\n",
      "0_2_1_1_\n",
      "0_2_1_2_\n",
      "0_2_2_0_\n",
      "0_2_2_1_\n",
      "0_2_2_2_\n",
      "1_0_0_0_\n",
      "1_0_0_1_\n",
      "1_0_0_2_\n",
      "1_0_1_0_\n",
      "1_0_1_1_\n",
      "1_0_1_2_\n",
      "1_0_2_0_\n",
      "1_0_2_1_\n",
      "1_0_2_2_\n",
      "1_1_0_0_\n",
      "1_1_0_1_\n",
      "1_1_0_2_\n",
      "1_1_1_0_\n",
      "1_1_1_1_\n",
      "1_1_1_2_\n",
      "1_1_2_0_\n",
      "1_1_2_1_\n",
      "1_1_2_2_\n",
      "1_2_0_0_\n",
      "1_2_0_1_\n",
      "1_2_0_2_\n",
      "1_2_1_0_\n",
      "1_2_1_1_\n",
      "1_2_1_2_\n",
      "1_2_2_0_\n",
      "1_2_2_1_\n",
      "1_2_2_2_\n",
      "2_0_0_0_\n",
      "2_0_0_1_\n",
      "2_0_0_2_\n",
      "2_0_1_0_\n",
      "2_0_1_1_\n",
      "2_0_1_2_\n",
      "2_0_2_0_\n",
      "2_0_2_1_\n",
      "2_0_2_2_\n",
      "2_1_0_0_\n",
      "2_1_0_1_\n",
      "2_1_0_2_\n",
      "2_1_1_0_\n",
      "2_1_1_1_\n",
      "2_1_1_2_\n",
      "2_1_2_0_\n",
      "2_1_2_1_\n",
      "2_1_2_2_\n",
      "2_2_0_0_\n",
      "2_2_0_1_\n",
      "2_2_0_2_\n",
      "2_2_1_0_\n",
      "2_2_1_1_\n",
      "2_2_1_2_\n",
      "2_2_2_0_\n",
      "2_2_2_1_\n",
      "2_2_2_2_\n"
     ]
    }
   ],
   "source": [
    "##### Sequence of 4 pattern, Open current\n",
    "data = np.array(hornet_data_upper_annular_train['close_current_states_kmean'])\n",
    "temp_df_close_current = seqof4_scoring(data)\n",
    "temp_df_close_current.to_csv(r'seqof4_close_current_pattern_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
